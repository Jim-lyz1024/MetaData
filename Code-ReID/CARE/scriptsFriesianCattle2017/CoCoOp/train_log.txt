2024-10-30 15:34:17,496 transreid INFO: Saving model in the path :D:\yil708\meta_data_all\MetaData\Code-ReID\CARE\scriptsFriesianCattle2017\CoCoOp
2024-10-30 15:34:17,496 transreid INFO: Namespace(config_file='configs/FriesianCattle2017/vit_clipreid.yml', opts=[], local_rank=0)
2024-10-30 15:34:17,496 transreid INFO: Loaded configuration file configs/FriesianCattle2017/vit_clipreid.yml
2024-10-30 15:34:17,496 transreid INFO: 
MODEL:
  PRETRAIN_CHOICE: 'imagenet'
  METRIC_LOSS_TYPE: 'triplet'
  IF_LABELSMOOTH: 'on'
  IF_WITH_CENTER: 'no'
  NAME: 'ViT-B-16'
  STRIDE_SIZE: [16, 16]
  ID_LOSS_WEIGHT : 0.25
  TRIPLET_LOSS_WEIGHT : 1.0
  I2T_LOSS_WEIGHT : 1.0
  # SIE_CAMERA: True
  # SIE_COE : 1.0

INPUT:
  SIZE_TRAIN: [256, 128]
  SIZE_TEST: [256, 128]
  PROB: 0.5 # random horizontal flip
  RE_PROB: 0.5 # random erasing
  PADDING: 10
  PIXEL_MEAN: [0.5, 0.5, 0.5]
  PIXEL_STD: [0.5, 0.5, 0.5]

DATALOADER:
  SAMPLER: 'softmax_triplet'
  NUM_INSTANCE: 4
  NUM_WORKERS: 8

SOLVER:
  STAGE1:
    IMS_PER_BATCH: 1
    OPTIMIZER_NAME: "Adam"
    BASE_LR: 0.00055
    WARMUP_LR_INIT: 0.00001
    LR_MIN: 1e-6
    WARMUP_METHOD: 'linear'
    WEIGHT_DECAY:  1e-4
    WEIGHT_DECAY_BIAS: 1e-4
    MAX_EPOCHS: 40
    CHECKPOINT_PERIOD: 40
    LOG_PERIOD: 250
    WARMUP_EPOCHS: 5
  
  STAGE2:
    IMS_PER_BATCH: 32
    OPTIMIZER_NAME: "Adam"
    BASE_LR: 0.000008
    WARMUP_METHOD: 'linear'
    WARMUP_ITERS: 10
    WARMUP_FACTOR: 0.1
    WEIGHT_DECAY:  0.0001
    WEIGHT_DECAY_BIAS: 0.0001
    LARGE_FC_LR: False
    MAX_EPOCHS: 60
    CHECKPOINT_PERIOD: 60
    LOG_PERIOD: 10
    EVAL_PERIOD: 60
    BIAS_LR_FACTOR: 2
    
    STEPS: [30, 50]
    GAMMA: 0.1
  
TEST:
  EVAL: True
  IMS_PER_BATCH: 64
  RE_RANKING: False
  WEIGHT: ''
  NECK_FEAT: 'before'
  FEAT_NORM: 'yes'



DATASETS:
   NAMES: ('friesiancattle2017')
  #  ROOT_DIR: ('/data/ywu840/dissertation')
   ROOT_DIR: ('D:\yil708\meta_data_all\MetaData\Code-ReID\CARE\data')
# OUTPUT_DIR: '/data/ywu840/dissertation/scripts/FriesianCattle2017/CoCoOp'
OUTPUT_DIR: 'D:\yil708\meta_data_all\MetaData\Code-ReID\CARE\scriptsFriesianCattle2017\CoCoOp'




# CUDA_VISIBLE_DEVICES=1 python train_clipreid.py --config_file configs/FriesianCattle2017/vit_clipreid.yml
2024-10-30 15:34:17,496 transreid INFO: Running with config:
DATALOADER:
  NUM_INSTANCE: 4
  NUM_WORKERS: 8
  SAMPLER: softmax_triplet
DATASETS:
  NAMES: friesiancattle2017
  ROOT_DIR: D:\yil708\meta_data_all\MetaData\Code-ReID\CARE\data
INPUT:
  PADDING: 10
  PIXEL_MEAN: [0.5, 0.5, 0.5]
  PIXEL_STD: [0.5, 0.5, 0.5]
  PROB: 0.5
  RE_PROB: 0.5
  SIZE_TEST: [256, 128]
  SIZE_TRAIN: [256, 128]
MODEL:
  ATT_DROP_RATE: 0.0
  COS_LAYER: False
  DEVICE: cuda
  DEVICE_ID: 0
  DIST_TRAIN: False
  DROP_OUT: 0.0
  DROP_PATH: 0.1
  I2T_LOSS_WEIGHT: 1.0
  ID_LOSS_TYPE: softmax
  ID_LOSS_WEIGHT: 0.25
  IF_LABELSMOOTH: on
  IF_WITH_CENTER: no
  LAST_STRIDE: 1
  METRIC_LOSS_TYPE: triplet
  NAME: ViT-B-16
  NECK: bnneck
  NO_MARGIN: False
  PRETRAIN_CHOICE: imagenet
  PRETRAIN_PATH: 
  SIE_CAMERA: False
  SIE_COE: 3.0
  SIE_VIEW: False
  STRIDE_SIZE: [16, 16]
  TRANSFORMER_TYPE: None
  TRIPLET_LOSS_WEIGHT: 1.0
OUTPUT_DIR: D:\yil708\meta_data_all\MetaData\Code-ReID\CARE\scriptsFriesianCattle2017\CoCoOp
SOLVER:
  MARGIN: 0.3
  SEED: 8402
  STAGE1:
    BASE_LR: 0.00055
    CHECKPOINT_PERIOD: 40
    COSINE_MARGIN: 0.5
    COSINE_SCALE: 30
    EVAL_PERIOD: 10
    IMS_PER_BATCH: 1
    LOG_PERIOD: 250
    LR_MIN: 1e-06
    MAX_EPOCHS: 40
    MOMENTUM: 0.9
    OPTIMIZER_NAME: Adam
    WARMUP_EPOCHS: 5
    WARMUP_FACTOR: 0.01
    WARMUP_ITERS: 500
    WARMUP_LR_INIT: 1e-05
    WARMUP_METHOD: linear
    WEIGHT_DECAY: 0.0001
    WEIGHT_DECAY_BIAS: 0.0001
  STAGE2:
    BASE_LR: 8e-06
    BIAS_LR_FACTOR: 2
    CENTER_LOSS_WEIGHT: 0.0005
    CENTER_LR: 0.5
    CHECKPOINT_PERIOD: 60
    COSINE_MARGIN: 0.5
    COSINE_SCALE: 30
    EVAL_PERIOD: 60
    GAMMA: 0.1
    IMS_PER_BATCH: 32
    LARGE_FC_LR: False
    LOG_PERIOD: 10
    LR_MIN: 1.6e-05
    MAX_EPOCHS: 60
    MOMENTUM: 0.9
    OPTIMIZER_NAME: Adam
    STEPS: (30, 50)
    WARMUP_EPOCHS: 5
    WARMUP_FACTOR: 0.1
    WARMUP_ITERS: 10
    WARMUP_LR_INIT: 0.01
    WARMUP_METHOD: linear
    WEIGHT_DECAY: 0.0001
    WEIGHT_DECAY_BIAS: 0.0001
TEST:
  DIST_MAT: dist_mat.npy
  EVAL: True
  FEAT_NORM: yes
  IMS_PER_BATCH: 64
  NECK_FEAT: before
  RE_RANKING: False
  WEIGHT: 
2024-10-30 15:35:50,533 transreid.train INFO: start training
2024-10-30 15:35:50,549 transreid.train INFO: model: build_transformer(
  (classifier): Linear(in_features=768, out_features=66, bias=False)
  (classifier_proj): Linear(in_features=512, out_features=66, bias=False)
  (bottleneck): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bottleneck_proj): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (image_encoder): VisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (prompt_learner): PromptLearner(
    (meta_net): Sequential(
      (linear1): Linear(in_features=512, out_features=32, bias=True)
      (relu): ReLU(inplace=True)
      (linear2): Linear(in_features=32, out_features=512, bias=True)
    )
  )
  (text_encoder): TextEncoder(
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
2024-10-30 15:36:49,750 transreid.train INFO: Epoch[1] Iteration[250/752] Loss: 2.035, Base Lr: 1.18e-04
2024-10-30 15:36:57,247 transreid.train INFO: Epoch[1] Iteration[500/752] Loss: 1.839, Base Lr: 1.18e-04
2024-10-30 15:37:05,955 transreid.train INFO: Epoch[1] Iteration[750/752] Loss: 1.748, Base Lr: 1.18e-04
2024-10-30 15:37:14,909 transreid.train INFO: Epoch[2] Iteration[250/752] Loss: 1.466, Base Lr: 2.26e-04
2024-10-30 15:37:23,140 transreid.train INFO: Epoch[2] Iteration[500/752] Loss: 1.424, Base Lr: 2.26e-04
2024-10-30 15:37:32,332 transreid.train INFO: Epoch[2] Iteration[750/752] Loss: 1.397, Base Lr: 2.26e-04
2024-10-30 15:37:40,106 transreid.train INFO: Epoch[3] Iteration[250/752] Loss: 1.309, Base Lr: 3.34e-04
2024-10-30 15:37:47,515 transreid.train INFO: Epoch[3] Iteration[500/752] Loss: 1.299, Base Lr: 3.34e-04
2024-10-30 15:37:56,502 transreid.train INFO: Epoch[3] Iteration[750/752] Loss: 1.289, Base Lr: 3.34e-04
2024-10-30 15:38:04,422 transreid.train INFO: Epoch[4] Iteration[250/752] Loss: 1.262, Base Lr: 4.42e-04
2024-10-30 15:38:13,751 transreid.train INFO: Epoch[4] Iteration[500/752] Loss: 1.258, Base Lr: 4.42e-04
2024-10-30 15:38:22,565 transreid.train INFO: Epoch[4] Iteration[750/752] Loss: 1.253, Base Lr: 4.42e-04
2024-10-30 15:38:31,879 transreid.train INFO: Epoch[5] Iteration[250/752] Loss: 1.235, Base Lr: 5.29e-04
2024-10-30 15:38:40,144 transreid.train INFO: Epoch[5] Iteration[500/752] Loss: 1.231, Base Lr: 5.29e-04
2024-10-30 15:38:47,938 transreid.train INFO: Epoch[5] Iteration[750/752] Loss: 1.229, Base Lr: 5.29e-04
2024-10-30 15:38:57,849 transreid.train INFO: Epoch[6] Iteration[250/752] Loss: 1.209, Base Lr: 5.20e-04
2024-10-30 15:39:06,223 transreid.train INFO: Epoch[6] Iteration[500/752] Loss: 1.209, Base Lr: 5.20e-04
2024-10-30 15:39:14,644 transreid.train INFO: Epoch[6] Iteration[750/752] Loss: 1.207, Base Lr: 5.20e-04
2024-10-30 15:39:23,788 transreid.train INFO: Epoch[7] Iteration[250/752] Loss: 1.198, Base Lr: 5.10e-04
2024-10-30 15:39:32,664 transreid.train INFO: Epoch[7] Iteration[500/752] Loss: 1.193, Base Lr: 5.10e-04
2024-10-30 15:39:41,401 transreid.train INFO: Epoch[7] Iteration[750/752] Loss: 1.190, Base Lr: 5.10e-04
2024-10-30 15:39:50,734 transreid.train INFO: Epoch[8] Iteration[250/752] Loss: 1.182, Base Lr: 4.98e-04
2024-10-30 15:39:59,115 transreid.train INFO: Epoch[8] Iteration[500/752] Loss: 1.180, Base Lr: 4.98e-04
2024-10-30 15:40:08,881 transreid.train INFO: Epoch[8] Iteration[750/752] Loss: 1.177, Base Lr: 4.98e-04
2024-10-30 15:40:17,115 transreid.train INFO: Epoch[9] Iteration[250/752] Loss: 1.168, Base Lr: 4.84e-04
2024-10-30 15:40:26,197 transreid.train INFO: Epoch[9] Iteration[500/752] Loss: 1.166, Base Lr: 4.84e-04
2024-10-30 15:40:34,450 transreid.train INFO: Epoch[9] Iteration[750/752] Loss: 1.165, Base Lr: 4.84e-04
2024-10-30 15:40:42,200 transreid.train INFO: Epoch[10] Iteration[250/752] Loss: 1.161, Base Lr: 4.70e-04
2024-10-30 15:40:52,190 transreid.train INFO: Epoch[10] Iteration[500/752] Loss: 1.159, Base Lr: 4.70e-04
2024-10-30 15:40:59,701 transreid.train INFO: Epoch[10] Iteration[750/752] Loss: 1.157, Base Lr: 4.70e-04
2024-10-30 15:41:09,076 transreid.train INFO: Epoch[11] Iteration[250/752] Loss: 1.142, Base Lr: 4.54e-04
2024-10-30 15:41:17,932 transreid.train INFO: Epoch[11] Iteration[500/752] Loss: 1.147, Base Lr: 4.54e-04
2024-10-30 15:41:27,218 transreid.train INFO: Epoch[11] Iteration[750/752] Loss: 1.148, Base Lr: 4.54e-04
2024-10-30 15:41:36,329 transreid.train INFO: Epoch[12] Iteration[250/752] Loss: 1.137, Base Lr: 4.37e-04
2024-10-30 15:41:45,049 transreid.train INFO: Epoch[12] Iteration[500/752] Loss: 1.138, Base Lr: 4.37e-04
2024-10-30 15:41:53,445 transreid.train INFO: Epoch[12] Iteration[750/752] Loss: 1.140, Base Lr: 4.37e-04
2024-10-30 15:42:02,222 transreid.train INFO: Epoch[13] Iteration[250/752] Loss: 1.133, Base Lr: 4.19e-04
2024-10-30 15:42:10,494 transreid.train INFO: Epoch[13] Iteration[500/752] Loss: 1.134, Base Lr: 4.19e-04
2024-10-30 15:42:19,964 transreid.train INFO: Epoch[13] Iteration[750/752] Loss: 1.132, Base Lr: 4.19e-04
2024-10-30 15:42:27,772 transreid.train INFO: Epoch[14] Iteration[250/752] Loss: 1.128, Base Lr: 4.00e-04
2024-10-30 15:42:36,592 transreid.train INFO: Epoch[14] Iteration[500/752] Loss: 1.126, Base Lr: 4.00e-04
2024-10-30 15:42:45,766 transreid.train INFO: Epoch[14] Iteration[750/752] Loss: 1.125, Base Lr: 4.00e-04
2024-10-30 15:42:54,282 transreid.train INFO: Epoch[15] Iteration[250/752] Loss: 1.122, Base Lr: 3.81e-04
2024-10-30 15:43:03,380 transreid.train INFO: Epoch[15] Iteration[500/752] Loss: 1.121, Base Lr: 3.81e-04
2024-10-30 15:43:12,045 transreid.train INFO: Epoch[15] Iteration[750/752] Loss: 1.122, Base Lr: 3.81e-04
2024-10-30 15:43:21,967 transreid.train INFO: Epoch[16] Iteration[250/752] Loss: 1.117, Base Lr: 3.60e-04
2024-10-30 15:43:30,677 transreid.train INFO: Epoch[16] Iteration[500/752] Loss: 1.118, Base Lr: 3.60e-04
2024-10-30 15:43:39,576 transreid.train INFO: Epoch[16] Iteration[750/752] Loss: 1.115, Base Lr: 3.60e-04
2024-10-30 15:43:49,227 transreid.train INFO: Epoch[17] Iteration[250/752] Loss: 1.108, Base Lr: 3.40e-04
2024-10-30 15:43:58,594 transreid.train INFO: Epoch[17] Iteration[500/752] Loss: 1.109, Base Lr: 3.40e-04
2024-10-30 15:44:07,065 transreid.train INFO: Epoch[17] Iteration[750/752] Loss: 1.109, Base Lr: 3.40e-04
2024-10-30 15:44:17,532 transreid.train INFO: Epoch[18] Iteration[250/752] Loss: 1.105, Base Lr: 3.18e-04
2024-10-30 15:44:25,297 transreid.train INFO: Epoch[18] Iteration[500/752] Loss: 1.106, Base Lr: 3.18e-04
2024-10-30 15:44:34,335 transreid.train INFO: Epoch[18] Iteration[750/752] Loss: 1.105, Base Lr: 3.18e-04
2024-10-30 15:44:43,402 transreid.train INFO: Epoch[19] Iteration[250/752] Loss: 1.099, Base Lr: 2.97e-04
2024-10-30 15:44:50,902 transreid.train INFO: Epoch[19] Iteration[500/752] Loss: 1.098, Base Lr: 2.97e-04
2024-10-30 15:44:59,309 transreid.train INFO: Epoch[19] Iteration[750/752] Loss: 1.098, Base Lr: 2.97e-04
2024-10-30 15:45:07,778 transreid.train INFO: Epoch[20] Iteration[250/752] Loss: 1.095, Base Lr: 2.76e-04
2024-10-30 15:45:14,885 transreid.train INFO: Epoch[20] Iteration[500/752] Loss: 1.094, Base Lr: 2.76e-04
2024-10-30 15:45:23,000 transreid.train INFO: Epoch[20] Iteration[750/752] Loss: 1.093, Base Lr: 2.76e-04
2024-10-30 15:45:30,995 transreid.train INFO: Epoch[21] Iteration[250/752] Loss: 1.089, Base Lr: 2.54e-04
2024-10-30 15:45:38,838 transreid.train INFO: Epoch[21] Iteration[500/752] Loss: 1.091, Base Lr: 2.54e-04
2024-10-30 15:45:47,919 transreid.train INFO: Epoch[21] Iteration[750/752] Loss: 1.090, Base Lr: 2.54e-04
2024-10-30 15:45:56,577 transreid.train INFO: Epoch[22] Iteration[250/752] Loss: 1.084, Base Lr: 2.33e-04
2024-10-30 15:46:04,106 transreid.train INFO: Epoch[22] Iteration[500/752] Loss: 1.085, Base Lr: 2.33e-04
2024-10-30 15:46:13,312 transreid.train INFO: Epoch[22] Iteration[750/752] Loss: 1.085, Base Lr: 2.33e-04
2024-10-30 15:46:21,905 transreid.train INFO: Epoch[23] Iteration[250/752] Loss: 1.083, Base Lr: 2.11e-04
2024-10-30 15:46:29,794 transreid.train INFO: Epoch[23] Iteration[500/752] Loss: 1.081, Base Lr: 2.11e-04
2024-10-30 15:46:38,107 transreid.train INFO: Epoch[23] Iteration[750/752] Loss: 1.081, Base Lr: 2.11e-04
2024-10-30 15:46:46,502 transreid.train INFO: Epoch[24] Iteration[250/752] Loss: 1.077, Base Lr: 1.91e-04
2024-10-30 15:46:55,082 transreid.train INFO: Epoch[24] Iteration[500/752] Loss: 1.079, Base Lr: 1.91e-04
2024-10-30 15:47:02,959 transreid.train INFO: Epoch[24] Iteration[750/752] Loss: 1.077, Base Lr: 1.91e-04
2024-10-30 15:47:11,868 transreid.train INFO: Epoch[25] Iteration[250/752] Loss: 1.075, Base Lr: 1.70e-04
2024-10-30 15:47:20,372 transreid.train INFO: Epoch[25] Iteration[500/752] Loss: 1.073, Base Lr: 1.70e-04
2024-10-30 15:47:28,212 transreid.train INFO: Epoch[25] Iteration[750/752] Loss: 1.073, Base Lr: 1.70e-04
2024-10-30 15:47:37,170 transreid.train INFO: Epoch[26] Iteration[250/752] Loss: 1.066, Base Lr: 1.51e-04
2024-10-30 15:47:45,781 transreid.train INFO: Epoch[26] Iteration[500/752] Loss: 1.068, Base Lr: 1.51e-04
2024-10-30 15:47:53,562 transreid.train INFO: Epoch[26] Iteration[750/752] Loss: 1.069, Base Lr: 1.51e-04
2024-10-30 15:48:02,237 transreid.train INFO: Epoch[27] Iteration[250/752] Loss: 1.066, Base Lr: 1.32e-04
2024-10-30 15:48:10,586 transreid.train INFO: Epoch[27] Iteration[500/752] Loss: 1.065, Base Lr: 1.32e-04
2024-10-30 15:48:18,658 transreid.train INFO: Epoch[27] Iteration[750/752] Loss: 1.066, Base Lr: 1.32e-04
2024-10-30 15:48:27,443 transreid.train INFO: Epoch[28] Iteration[250/752] Loss: 1.061, Base Lr: 1.14e-04
2024-10-30 15:48:35,668 transreid.train INFO: Epoch[28] Iteration[500/752] Loss: 1.061, Base Lr: 1.14e-04
2024-10-30 15:48:44,006 transreid.train INFO: Epoch[28] Iteration[750/752] Loss: 1.062, Base Lr: 1.14e-04
2024-10-30 15:48:52,995 transreid.train INFO: Epoch[29] Iteration[250/752] Loss: 1.061, Base Lr: 9.72e-05
2024-10-30 15:49:01,887 transreid.train INFO: Epoch[29] Iteration[500/752] Loss: 1.061, Base Lr: 9.72e-05
2024-10-30 15:49:09,948 transreid.train INFO: Epoch[29] Iteration[750/752] Loss: 1.060, Base Lr: 9.72e-05
2024-10-30 15:49:18,449 transreid.train INFO: Epoch[30] Iteration[250/752] Loss: 1.055, Base Lr: 8.14e-05
2024-10-30 15:49:27,157 transreid.train INFO: Epoch[30] Iteration[500/752] Loss: 1.057, Base Lr: 8.14e-05
2024-10-30 15:49:35,374 transreid.train INFO: Epoch[30] Iteration[750/752] Loss: 1.057, Base Lr: 8.14e-05
2024-10-30 15:49:43,768 transreid.train INFO: Epoch[31] Iteration[250/752] Loss: 1.056, Base Lr: 6.68e-05
2024-10-30 15:49:52,192 transreid.train INFO: Epoch[31] Iteration[500/752] Loss: 1.056, Base Lr: 6.68e-05
2024-10-30 15:50:00,521 transreid.train INFO: Epoch[31] Iteration[750/752] Loss: 1.055, Base Lr: 6.68e-05
2024-10-30 15:50:08,863 transreid.train INFO: Epoch[32] Iteration[250/752] Loss: 1.051, Base Lr: 5.34e-05
2024-10-30 15:50:17,441 transreid.train INFO: Epoch[32] Iteration[500/752] Loss: 1.053, Base Lr: 5.34e-05
2024-10-30 15:50:25,927 transreid.train INFO: Epoch[32] Iteration[750/752] Loss: 1.053, Base Lr: 5.34e-05
2024-10-30 15:50:34,460 transreid.train INFO: Epoch[33] Iteration[250/752] Loss: 1.048, Base Lr: 4.15e-05
2024-10-30 15:50:43,101 transreid.train INFO: Epoch[33] Iteration[500/752] Loss: 1.051, Base Lr: 4.15e-05
2024-10-30 15:50:51,602 transreid.train INFO: Epoch[33] Iteration[750/752] Loss: 1.052, Base Lr: 4.15e-05
2024-10-30 15:50:59,727 transreid.train INFO: Epoch[34] Iteration[250/752] Loss: 1.050, Base Lr: 3.09e-05
2024-10-30 15:51:08,621 transreid.train INFO: Epoch[34] Iteration[500/752] Loss: 1.050, Base Lr: 3.09e-05
2024-10-30 15:51:17,181 transreid.train INFO: Epoch[34] Iteration[750/752] Loss: 1.050, Base Lr: 3.09e-05
2024-10-30 15:51:25,636 transreid.train INFO: Epoch[35] Iteration[250/752] Loss: 1.045, Base Lr: 2.19e-05
2024-10-30 15:51:34,343 transreid.train INFO: Epoch[35] Iteration[500/752] Loss: 1.047, Base Lr: 2.19e-05
2024-10-30 15:51:43,073 transreid.train INFO: Epoch[35] Iteration[750/752] Loss: 1.049, Base Lr: 2.19e-05
2024-10-30 15:51:51,365 transreid.train INFO: Epoch[36] Iteration[250/752] Loss: 1.050, Base Lr: 1.44e-05
2024-10-30 15:51:59,628 transreid.train INFO: Epoch[36] Iteration[500/752] Loss: 1.049, Base Lr: 1.44e-05
2024-10-30 15:52:08,695 transreid.train INFO: Epoch[36] Iteration[750/752] Loss: 1.049, Base Lr: 1.44e-05
2024-10-30 15:52:17,034 transreid.train INFO: Epoch[37] Iteration[250/752] Loss: 1.048, Base Lr: 8.58e-06
2024-10-30 15:52:25,349 transreid.train INFO: Epoch[37] Iteration[500/752] Loss: 1.047, Base Lr: 8.58e-06
2024-10-30 15:52:34,259 transreid.train INFO: Epoch[37] Iteration[750/752] Loss: 1.048, Base Lr: 8.58e-06
2024-10-30 15:52:43,018 transreid.train INFO: Epoch[38] Iteration[250/752] Loss: 1.047, Base Lr: 4.38e-06
2024-10-30 15:52:51,486 transreid.train INFO: Epoch[38] Iteration[500/752] Loss: 1.047, Base Lr: 4.38e-06
2024-10-30 15:53:00,451 transreid.train INFO: Epoch[38] Iteration[750/752] Loss: 1.048, Base Lr: 4.38e-06
2024-10-30 15:53:09,064 transreid.train INFO: Epoch[39] Iteration[250/752] Loss: 1.046, Base Lr: 1.85e-06
2024-10-30 15:53:18,129 transreid.train INFO: Epoch[39] Iteration[500/752] Loss: 1.047, Base Lr: 1.85e-06
2024-10-30 15:53:26,474 transreid.train INFO: Epoch[39] Iteration[750/752] Loss: 1.047, Base Lr: 1.85e-06
2024-10-30 15:53:35,178 transreid.train INFO: Epoch[40] Iteration[250/752] Loss: 1.049, Base Lr: 1.00e-06
2024-10-30 15:53:43,534 transreid.train INFO: Epoch[40] Iteration[500/752] Loss: 1.047, Base Lr: 1.00e-06
2024-10-30 15:53:51,911 transreid.train INFO: Epoch[40] Iteration[750/752] Loss: 1.047, Base Lr: 1.00e-06
2024-10-30 15:53:53,092 transreid.train INFO: Stage1 running time: 0:18:02.563000
2024-10-30 15:53:53,104 transreid.train INFO: start training
2024-10-30 15:55:40,136 transreid.train INFO: Epoch[1] Iteration[10/22] Loss: 15.090, Acc: 0.006, Base Lr: 1.52e-06
2024-10-30 15:55:40,953 transreid.train INFO: Epoch[1] Iteration[20/22] Loss: 12.730, Acc: 0.006, Base Lr: 1.52e-06
2024-10-30 15:55:41,989 transreid.train INFO: Epoch 1 done. Time per batch: 2.150[s] Speed: 14.9[samples/s]
2024-10-30 15:56:24,432 transreid.train INFO: Epoch[2] Iteration[10/22] Loss: 9.472, Acc: 0.003, Base Lr: 2.24e-06
2024-10-30 15:56:26,320 transreid.train INFO: Epoch 2 done. Time per batch: 2.333[s] Speed: 13.7[samples/s]
2024-10-30 15:57:08,961 transreid.train INFO: Epoch[3] Iteration[10/22] Loss: 8.134, Acc: 0.000, Base Lr: 2.96e-06
2024-10-30 15:57:09,824 transreid.train INFO: Epoch[3] Iteration[20/22] Loss: 7.718, Acc: 0.003, Base Lr: 2.96e-06
2024-10-30 15:57:10,829 transreid.train INFO: Epoch 3 done. Time per batch: 2.225[s] Speed: 14.4[samples/s]
2024-10-30 15:57:52,084 transreid.train INFO: Epoch[4] Iteration[10/22] Loss: 7.596, Acc: 0.000, Base Lr: 3.68e-06
2024-10-30 15:57:52,979 transreid.train INFO: Epoch[4] Iteration[20/22] Loss: 7.176, Acc: 0.005, Base Lr: 3.68e-06
2024-10-30 15:57:53,827 transreid.train INFO: Epoch 4 done. Time per batch: 2.048[s] Speed: 15.6[samples/s]
2024-10-30 15:58:37,029 transreid.train INFO: Epoch[5] Iteration[10/22] Loss: 7.446, Acc: 0.000, Base Lr: 4.40e-06
2024-10-30 15:58:38,670 transreid.train INFO: Epoch 5 done. Time per batch: 2.360[s] Speed: 13.6[samples/s]
2024-10-30 15:59:19,319 transreid.train INFO: Epoch[6] Iteration[10/22] Loss: 7.231, Acc: 0.000, Base Lr: 5.12e-06
2024-10-30 15:59:20,136 transreid.train INFO: Epoch[6] Iteration[20/22] Loss: 6.778, Acc: 0.028, Base Lr: 5.12e-06
2024-10-30 15:59:20,889 transreid.train INFO: Epoch 6 done. Time per batch: 2.111[s] Speed: 15.2[samples/s]
2024-10-30 16:00:02,368 transreid.train INFO: Epoch[7] Iteration[10/22] Loss: 7.189, Acc: 0.019, Base Lr: 5.84e-06
2024-10-30 16:00:03,294 transreid.train INFO: Epoch[7] Iteration[20/22] Loss: 6.658, Acc: 0.038, Base Lr: 5.84e-06
2024-10-30 16:00:04,062 transreid.train INFO: Epoch 7 done. Time per batch: 2.159[s] Speed: 14.8[samples/s]
2024-10-30 16:00:44,884 transreid.train INFO: Epoch[8] Iteration[10/22] Loss: 6.897, Acc: 0.000, Base Lr: 6.56e-06
2024-10-30 16:00:45,732 transreid.train INFO: Epoch[8] Iteration[20/22] Loss: 6.376, Acc: 0.087, Base Lr: 6.56e-06
2024-10-30 16:00:46,580 transreid.train INFO: Epoch 8 done. Time per batch: 2.126[s] Speed: 15.1[samples/s]
2024-10-30 16:01:27,174 transreid.train INFO: Epoch[9] Iteration[10/22] Loss: 6.720, Acc: 0.100, Base Lr: 7.28e-06
2024-10-30 16:01:28,042 transreid.train INFO: Epoch[9] Iteration[20/22] Loss: 6.186, Acc: 0.123, Base Lr: 7.28e-06
2024-10-30 16:01:28,796 transreid.train INFO: Epoch 9 done. Time per batch: 2.111[s] Speed: 15.2[samples/s]
2024-10-30 16:02:09,556 transreid.train INFO: Epoch[10] Iteration[10/22] Loss: 6.463, Acc: 0.081, Base Lr: 8.00e-06
2024-10-30 16:02:10,576 transreid.train INFO: Epoch[10] Iteration[20/22] Loss: 6.052, Acc: 0.167, Base Lr: 8.00e-06
2024-10-30 16:02:11,348 transreid.train INFO: Epoch 10 done. Time per batch: 2.128[s] Speed: 15.0[samples/s]
2024-10-30 16:02:47,274 transreid.train INFO: Epoch[11] Iteration[10/22] Loss: 6.293, Acc: 0.184, Base Lr: 8.00e-06
2024-10-30 16:02:48,654 transreid.train INFO: Epoch 11 done. Time per batch: 1.963[s] Speed: 16.3[samples/s]
2024-10-30 16:03:24,710 transreid.train INFO: Epoch[12] Iteration[10/22] Loss: 6.334, Acc: 0.141, Base Lr: 8.00e-06
2024-10-30 16:03:25,448 transreid.train INFO: Epoch[12] Iteration[20/22] Loss: 5.817, Acc: 0.291, Base Lr: 8.00e-06
2024-10-30 16:03:26,169 transreid.train INFO: Epoch 12 done. Time per batch: 1.876[s] Speed: 17.1[samples/s]
2024-10-30 16:04:03,268 transreid.train INFO: Epoch[13] Iteration[10/22] Loss: 6.027, Acc: 0.228, Base Lr: 8.00e-06
2024-10-30 16:04:04,006 transreid.train INFO: Epoch[13] Iteration[20/22] Loss: 5.546, Acc: 0.314, Base Lr: 8.00e-06
2024-10-30 16:04:04,805 transreid.train INFO: Epoch 13 done. Time per batch: 1.840[s] Speed: 17.4[samples/s]
2024-10-30 16:04:40,243 transreid.train INFO: Epoch[14] Iteration[10/22] Loss: 5.911, Acc: 0.278, Base Lr: 8.00e-06
2024-10-30 16:04:41,090 transreid.train INFO: Epoch[14] Iteration[20/22] Loss: 5.374, Acc: 0.431, Base Lr: 8.00e-06
2024-10-30 16:04:41,812 transreid.train INFO: Epoch 14 done. Time per batch: 1.850[s] Speed: 17.3[samples/s]
2024-10-30 16:05:16,816 transreid.train INFO: Epoch[15] Iteration[10/22] Loss: 5.646, Acc: 0.284, Base Lr: 8.00e-06
2024-10-30 16:05:17,566 transreid.train INFO: Epoch[15] Iteration[20/22] Loss: 5.085, Acc: 0.444, Base Lr: 8.00e-06
2024-10-30 16:05:18,351 transreid.train INFO: Epoch 15 done. Time per batch: 1.827[s] Speed: 17.5[samples/s]
2024-10-30 16:05:53,662 transreid.train INFO: Epoch[16] Iteration[10/22] Loss: 5.250, Acc: 0.309, Base Lr: 8.00e-06
2024-10-30 16:05:55,074 transreid.train INFO: Epoch 16 done. Time per batch: 1.933[s] Speed: 16.6[samples/s]
2024-10-30 16:06:30,427 transreid.train INFO: Epoch[17] Iteration[10/22] Loss: 5.380, Acc: 0.319, Base Lr: 8.00e-06
2024-10-30 16:06:31,965 transreid.train INFO: Epoch 17 done. Time per batch: 1.942[s] Speed: 16.5[samples/s]
2024-10-30 16:07:07,343 transreid.train INFO: Epoch[18] Iteration[10/22] Loss: 5.535, Acc: 0.275, Base Lr: 8.00e-06
2024-10-30 16:07:08,190 transreid.train INFO: Epoch[18] Iteration[20/22] Loss: 4.733, Acc: 0.520, Base Lr: 8.00e-06
2024-10-30 16:07:08,916 transreid.train INFO: Epoch 18 done. Time per batch: 1.848[s] Speed: 17.3[samples/s]
2024-10-30 16:07:45,301 transreid.train INFO: Epoch[19] Iteration[10/22] Loss: 4.871, Acc: 0.347, Base Lr: 8.00e-06
2024-10-30 16:07:46,854 transreid.train INFO: Epoch 19 done. Time per batch: 1.997[s] Speed: 16.0[samples/s]
2024-10-30 16:08:22,980 transreid.train INFO: Epoch[20] Iteration[10/22] Loss: 4.889, Acc: 0.497, Base Lr: 8.00e-06
2024-10-30 16:08:24,377 transreid.train INFO: Epoch 20 done. Time per batch: 2.085[s] Speed: 15.4[samples/s]
2024-10-30 16:09:00,205 transreid.train INFO: Epoch[21] Iteration[10/22] Loss: 4.663, Acc: 0.497, Base Lr: 8.00e-06
2024-10-30 16:09:01,037 transreid.train INFO: Epoch[21] Iteration[20/22] Loss: 4.114, Acc: 0.694, Base Lr: 8.00e-06
2024-10-30 16:09:01,743 transreid.train INFO: Epoch 21 done. Time per batch: 1.868[s] Speed: 17.1[samples/s]
2024-10-30 16:09:36,600 transreid.train INFO: Epoch[22] Iteration[10/22] Loss: 4.765, Acc: 0.525, Base Lr: 8.00e-06
2024-10-30 16:09:38,013 transreid.train INFO: Epoch 22 done. Time per batch: 1.909[s] Speed: 16.8[samples/s]
2024-10-30 16:10:13,862 transreid.train INFO: Epoch[23] Iteration[10/22] Loss: 4.476, Acc: 0.584, Base Lr: 8.00e-06
2024-10-30 16:10:15,462 transreid.train INFO: Epoch 23 done. Time per batch: 1.971[s] Speed: 16.2[samples/s]
2024-10-30 16:10:51,352 transreid.train INFO: Epoch[24] Iteration[10/22] Loss: 4.719, Acc: 0.581, Base Lr: 8.00e-06
2024-10-30 16:10:52,142 transreid.train INFO: Epoch[24] Iteration[20/22] Loss: 4.075, Acc: 0.738, Base Lr: 8.00e-06
2024-10-30 16:10:52,874 transreid.train INFO: Epoch 24 done. Time per batch: 1.871[s] Speed: 17.1[samples/s]
2024-10-30 16:11:28,550 transreid.train INFO: Epoch[25] Iteration[10/22] Loss: 4.211, Acc: 0.559, Base Lr: 8.00e-06
2024-10-30 16:11:29,413 transreid.train INFO: Epoch[25] Iteration[20/22] Loss: 3.848, Acc: 0.709, Base Lr: 8.00e-06
2024-10-30 16:11:30,151 transreid.train INFO: Epoch 25 done. Time per batch: 1.864[s] Speed: 17.2[samples/s]
2024-10-30 16:12:05,335 transreid.train INFO: Epoch[26] Iteration[10/22] Loss: 4.155, Acc: 0.619, Base Lr: 8.00e-06
2024-10-30 16:12:06,105 transreid.train INFO: Epoch[26] Iteration[20/22] Loss: 3.784, Acc: 0.736, Base Lr: 8.00e-06
2024-10-30 16:12:06,842 transreid.train INFO: Epoch 26 done. Time per batch: 1.835[s] Speed: 17.4[samples/s]
2024-10-30 16:12:41,904 transreid.train INFO: Epoch[27] Iteration[10/22] Loss: 4.076, Acc: 0.694, Base Lr: 8.00e-06
2024-10-30 16:12:42,642 transreid.train INFO: Epoch[27] Iteration[20/22] Loss: 3.719, Acc: 0.803, Base Lr: 8.00e-06
2024-10-30 16:12:43,379 transreid.train INFO: Epoch 27 done. Time per batch: 1.827[s] Speed: 17.5[samples/s]
2024-10-30 16:13:20,306 transreid.train INFO: Epoch[28] Iteration[10/22] Loss: 4.119, Acc: 0.681, Base Lr: 8.00e-06
2024-10-30 16:13:21,058 transreid.train INFO: Epoch[28] Iteration[20/22] Loss: 3.629, Acc: 0.809, Base Lr: 8.00e-06
2024-10-30 16:13:21,796 transreid.train INFO: Epoch 28 done. Time per batch: 1.921[s] Speed: 16.7[samples/s]
2024-10-30 16:13:58,883 transreid.train INFO: Epoch[29] Iteration[10/22] Loss: 4.029, Acc: 0.700, Base Lr: 8.00e-06
2024-10-30 16:14:00,404 transreid.train INFO: Epoch 29 done. Time per batch: 2.032[s] Speed: 15.7[samples/s]
2024-10-30 16:14:37,010 transreid.train INFO: Epoch[30] Iteration[10/22] Loss: 3.868, Acc: 0.697, Base Lr: 8.00e-07
2024-10-30 16:14:37,700 transreid.train INFO: Epoch[30] Iteration[20/22] Loss: 3.478, Acc: 0.828, Base Lr: 8.00e-07
2024-10-30 16:14:38,453 transreid.train INFO: Epoch 30 done. Time per batch: 1.902[s] Speed: 16.8[samples/s]
2024-10-30 16:15:16,306 transreid.train INFO: Epoch[31] Iteration[10/22] Loss: 3.652, Acc: 0.781, Base Lr: 8.00e-07
2024-10-30 16:15:17,184 transreid.train INFO: Epoch[31] Iteration[20/22] Loss: 3.349, Acc: 0.870, Base Lr: 8.00e-07
2024-10-30 16:15:18,048 transreid.train INFO: Epoch 31 done. Time per batch: 1.979[s] Speed: 16.2[samples/s]
2024-10-30 16:15:56,229 transreid.train INFO: Epoch[32] Iteration[10/22] Loss: 3.602, Acc: 0.831, Base Lr: 8.00e-07
2024-10-30 16:15:57,155 transreid.train INFO: Epoch[32] Iteration[20/22] Loss: 3.342, Acc: 0.886, Base Lr: 8.00e-07
2024-10-30 16:15:58,018 transreid.train INFO: Epoch 32 done. Time per batch: 1.903[s] Speed: 16.8[samples/s]
2024-10-30 16:16:36,674 transreid.train INFO: Epoch[33] Iteration[10/22] Loss: 3.641, Acc: 0.797, Base Lr: 8.00e-07
2024-10-30 16:16:37,489 transreid.train INFO: Epoch[33] Iteration[20/22] Loss: 3.341, Acc: 0.881, Base Lr: 8.00e-07
2024-10-30 16:16:38,275 transreid.train INFO: Epoch 33 done. Time per batch: 2.013[s] Speed: 15.9[samples/s]
2024-10-30 16:17:17,229 transreid.train INFO: Epoch[34] Iteration[10/22] Loss: 3.729, Acc: 0.812, Base Lr: 8.00e-07
2024-10-30 16:17:18,045 transreid.train INFO: Epoch[34] Iteration[20/22] Loss: 3.362, Acc: 0.878, Base Lr: 8.00e-07
2024-10-30 16:17:18,814 transreid.train INFO: Epoch 34 done. Time per batch: 2.027[s] Speed: 15.8[samples/s]
2024-10-30 16:17:58,447 transreid.train INFO: Epoch[35] Iteration[10/22] Loss: 3.529, Acc: 0.844, Base Lr: 8.00e-07
2024-10-30 16:17:59,263 transreid.train INFO: Epoch[35] Iteration[20/22] Loss: 3.257, Acc: 0.897, Base Lr: 8.00e-07
2024-10-30 16:18:00,047 transreid.train INFO: Epoch 35 done. Time per batch: 2.062[s] Speed: 15.5[samples/s]
2024-10-30 16:18:43,048 transreid.train INFO: Epoch[36] Iteration[10/22] Loss: 3.570, Acc: 0.825, Base Lr: 8.00e-07
2024-10-30 16:18:44,528 transreid.train INFO: Epoch 36 done. Time per batch: 2.471[s] Speed: 12.9[samples/s]
2024-10-30 16:19:23,717 transreid.train INFO: Epoch[37] Iteration[10/22] Loss: 3.477, Acc: 0.819, Base Lr: 8.00e-07
2024-10-30 16:19:24,517 transreid.train INFO: Epoch[37] Iteration[20/22] Loss: 3.227, Acc: 0.895, Base Lr: 8.00e-07
2024-10-30 16:19:25,285 transreid.train INFO: Epoch 37 done. Time per batch: 2.038[s] Speed: 15.7[samples/s]
2024-10-30 16:20:03,552 transreid.train INFO: Epoch[38] Iteration[10/22] Loss: 3.617, Acc: 0.812, Base Lr: 8.00e-07
2024-10-30 16:20:05,107 transreid.train INFO: Epoch 38 done. Time per batch: 2.096[s] Speed: 15.3[samples/s]
2024-10-30 16:20:43,825 transreid.train INFO: Epoch[39] Iteration[10/22] Loss: 3.596, Acc: 0.859, Base Lr: 8.00e-07
2024-10-30 16:20:44,594 transreid.train INFO: Epoch[39] Iteration[20/22] Loss: 3.296, Acc: 0.914, Base Lr: 8.00e-07
2024-10-30 16:20:45,378 transreid.train INFO: Epoch 39 done. Time per batch: 2.014[s] Speed: 15.9[samples/s]
2024-10-30 16:21:23,891 transreid.train INFO: Epoch[40] Iteration[10/22] Loss: 3.452, Acc: 0.853, Base Lr: 8.00e-07
2024-10-30 16:21:25,413 transreid.train INFO: Epoch 40 done. Time per batch: 2.107[s] Speed: 15.2[samples/s]
2024-10-30 16:22:03,759 transreid.train INFO: Epoch[41] Iteration[10/22] Loss: 3.481, Acc: 0.825, Base Lr: 8.00e-07
2024-10-30 16:22:05,360 transreid.train INFO: Epoch 41 done. Time per batch: 2.102[s] Speed: 15.2[samples/s]
2024-10-30 16:22:46,176 transreid.train INFO: Epoch[42] Iteration[10/22] Loss: 3.423, Acc: 0.834, Base Lr: 8.00e-07
2024-10-30 16:22:47,040 transreid.train INFO: Epoch[42] Iteration[20/22] Loss: 3.173, Acc: 0.903, Base Lr: 8.00e-07
2024-10-30 16:22:47,903 transreid.train INFO: Epoch 42 done. Time per batch: 2.127[s] Speed: 15.0[samples/s]
2024-10-30 16:23:32,011 transreid.train INFO: Epoch[43] Iteration[10/22] Loss: 3.538, Acc: 0.844, Base Lr: 8.00e-07
2024-10-30 16:23:33,705 transreid.train INFO: Epoch 43 done. Time per batch: 2.411[s] Speed: 13.3[samples/s]
2024-10-30 16:24:13,193 transreid.train INFO: Epoch[44] Iteration[10/22] Loss: 3.510, Acc: 0.850, Base Lr: 8.00e-07
2024-10-30 16:24:14,055 transreid.train INFO: Epoch[44] Iteration[20/22] Loss: 3.182, Acc: 0.916, Base Lr: 8.00e-07
2024-10-30 16:24:14,840 transreid.train INFO: Epoch 44 done. Time per batch: 2.057[s] Speed: 15.6[samples/s]
2024-10-30 16:24:55,300 transreid.train INFO: Epoch[45] Iteration[10/22] Loss: 3.567, Acc: 0.856, Base Lr: 8.00e-07
2024-10-30 16:24:56,101 transreid.train INFO: Epoch[45] Iteration[20/22] Loss: 3.256, Acc: 0.922, Base Lr: 8.00e-07
2024-10-30 16:24:56,869 transreid.train INFO: Epoch 45 done. Time per batch: 2.101[s] Speed: 15.2[samples/s]
2024-10-30 16:25:36,124 transreid.train INFO: Epoch[46] Iteration[10/22] Loss: 3.664, Acc: 0.859, Base Lr: 8.00e-07
2024-10-30 16:25:36,955 transreid.train INFO: Epoch[46] Iteration[20/22] Loss: 3.285, Acc: 0.917, Base Lr: 8.00e-07
2024-10-30 16:25:37,771 transreid.train INFO: Epoch 46 done. Time per batch: 2.045[s] Speed: 15.6[samples/s]
2024-10-30 16:26:16,742 transreid.train INFO: Epoch[47] Iteration[10/22] Loss: 3.404, Acc: 0.872, Base Lr: 8.00e-07
2024-10-30 16:26:18,201 transreid.train INFO: Epoch 47 done. Time per batch: 2.246[s] Speed: 14.2[samples/s]
2024-10-30 16:26:57,310 transreid.train INFO: Epoch[48] Iteration[10/22] Loss: 3.485, Acc: 0.847, Base Lr: 8.00e-07
2024-10-30 16:26:58,140 transreid.train INFO: Epoch[48] Iteration[20/22] Loss: 3.213, Acc: 0.913, Base Lr: 8.00e-07
2024-10-30 16:26:58,894 transreid.train INFO: Epoch 48 done. Time per batch: 2.035[s] Speed: 15.7[samples/s]
2024-10-30 16:27:37,849 transreid.train INFO: Epoch[49] Iteration[10/22] Loss: 3.369, Acc: 0.909, Base Lr: 8.00e-07
2024-10-30 16:27:38,736 transreid.train INFO: Epoch[49] Iteration[20/22] Loss: 3.135, Acc: 0.933, Base Lr: 8.00e-07
2024-10-30 16:27:39,481 transreid.train INFO: Epoch 49 done. Time per batch: 2.029[s] Speed: 15.8[samples/s]
2024-10-30 16:28:18,675 transreid.train INFO: Epoch[50] Iteration[10/22] Loss: 3.489, Acc: 0.872, Base Lr: 8.00e-08
2024-10-30 16:28:19,506 transreid.train INFO: Epoch[50] Iteration[20/22] Loss: 3.186, Acc: 0.931, Base Lr: 8.00e-08
2024-10-30 16:28:20,322 transreid.train INFO: Epoch 50 done. Time per batch: 2.041[s] Speed: 15.7[samples/s]
2024-10-30 16:28:59,281 transreid.train INFO: Epoch[51] Iteration[10/22] Loss: 3.414, Acc: 0.863, Base Lr: 8.00e-08
2024-10-30 16:29:00,943 transreid.train INFO: Epoch 51 done. Time per batch: 2.138[s] Speed: 15.0[samples/s]
2024-10-30 16:29:39,840 transreid.train INFO: Epoch[52] Iteration[10/22] Loss: 3.382, Acc: 0.891, Base Lr: 8.00e-08
2024-10-30 16:29:40,656 transreid.train INFO: Epoch[52] Iteration[20/22] Loss: 3.121, Acc: 0.927, Base Lr: 8.00e-08
2024-10-30 16:29:41,410 transreid.train INFO: Epoch 52 done. Time per batch: 2.023[s] Speed: 15.8[samples/s]
2024-10-30 16:30:20,415 transreid.train INFO: Epoch[53] Iteration[10/22] Loss: 3.461, Acc: 0.866, Base Lr: 8.00e-08
2024-10-30 16:30:21,230 transreid.train INFO: Epoch[53] Iteration[20/22] Loss: 3.152, Acc: 0.923, Base Lr: 8.00e-08
2024-10-30 16:30:21,984 transreid.train INFO: Epoch 53 done. Time per batch: 2.029[s] Speed: 15.8[samples/s]
2024-10-30 16:31:01,190 transreid.train INFO: Epoch[54] Iteration[10/22] Loss: 3.585, Acc: 0.878, Base Lr: 8.00e-08
2024-10-30 16:31:02,664 transreid.train INFO: Epoch 54 done. Time per batch: 2.141[s] Speed: 14.9[samples/s]
2024-10-30 16:31:41,415 transreid.train INFO: Epoch[55] Iteration[10/22] Loss: 3.347, Acc: 0.881, Base Lr: 8.00e-08
2024-10-30 16:31:42,905 transreid.train INFO: Epoch 55 done. Time per batch: 2.118[s] Speed: 15.1[samples/s]
2024-10-30 16:32:21,764 transreid.train INFO: Epoch[56] Iteration[10/22] Loss: 3.374, Acc: 0.897, Base Lr: 8.00e-08
2024-10-30 16:32:23,317 transreid.train INFO: Epoch 56 done. Time per batch: 2.127[s] Speed: 15.0[samples/s]
2024-10-30 16:33:02,012 transreid.train INFO: Epoch[57] Iteration[10/22] Loss: 3.446, Acc: 0.875, Base Lr: 8.00e-08
2024-10-30 16:33:02,730 transreid.train INFO: Epoch[57] Iteration[20/22] Loss: 3.131, Acc: 0.928, Base Lr: 8.00e-08
2024-10-30 16:33:03,484 transreid.train INFO: Epoch 57 done. Time per batch: 2.008[s] Speed: 15.9[samples/s]
2024-10-30 16:33:46,119 transreid.train INFO: Epoch[58] Iteration[10/22] Loss: 3.521, Acc: 0.872, Base Lr: 8.00e-08
2024-10-30 16:33:47,013 transreid.train INFO: Epoch[58] Iteration[20/22] Loss: 3.178, Acc: 0.933, Base Lr: 8.00e-08
2024-10-30 16:33:47,782 transreid.train INFO: Epoch 58 done. Time per batch: 2.215[s] Speed: 14.4[samples/s]
2024-10-30 16:34:26,942 transreid.train INFO: Epoch[59] Iteration[10/22] Loss: 3.336, Acc: 0.878, Base Lr: 8.00e-08
2024-10-30 16:34:28,412 transreid.train INFO: Epoch 59 done. Time per batch: 2.138[s] Speed: 15.0[samples/s]
2024-10-30 16:35:07,338 transreid.train INFO: Epoch[60] Iteration[10/22] Loss: 3.504, Acc: 0.853, Base Lr: 8.00e-08
2024-10-30 16:35:08,907 transreid.train INFO: Epoch 60 done. Time per batch: 2.131[s] Speed: 15.0[samples/s]
2024-10-30 16:35:50,342 transreid.train INFO: Validation Results - Epoch: 60
2024-10-30 16:35:50,342 transreid.train INFO: mAP: 94.7%
2024-10-30 16:35:50,342 transreid.train INFO: CMC curve, Rank-1  :100.0%
2024-10-30 16:35:50,342 transreid.train INFO: CMC curve, Rank-5  :100.0%
2024-10-30 16:35:50,342 transreid.train INFO: CMC curve, Rank-10 :100.0%
2024-10-30 16:35:50,358 transreid.train INFO: Total running time: 0:41:57.250000
